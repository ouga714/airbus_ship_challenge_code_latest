#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
airbus_detector_effnetv2_precision_momos.py

Airbus Ship Detection (Kaggle) — ship-present vs ship-absent Detector (image-level binary classifier)
Goal (practical): Build a high-precision classifier that avoids "suspicious => POS" behavior.
- Model: torchvision EfficientNetV2 (default: efficientnet_v2_s)
- Input size: 768x768 (default)
- Training: FP32 only (NO AMP)
- Dataset population (IMPORTANT): use ALL images in train_v2 directory (do NOT lose ship-negative images)
- Labels: train_ship_segmentations_v2.csv — POS if an ImageId has at least one non-empty RLE row

Key design for "High Precision" behavior:
- Threshold selection on VAL: choose threshold that maximizes ACCURACY under Precision >= min_precision (default 0.98)
  (This intentionally allows misses / FN if needed to avoid false alarms / FP.)

Augmentation:
- POS: stronger augmentation (to increase effective samples) + optional ship-aware bbox crop (cheap; no inpainting)
- NEG: mild augmentation
- No subsampling of dataset population. Oversampling is done via WeightedRandomSampler (replacement) without dropping any IDs.

Outputs:
  <out_dir>/<run_name>/
    - best_model.pt
    - last_model.pt
    - splits.json
    - config.json
    - metrics_val_best.json
    - train.log

Assumed dataset layout (momos / inside docker):
  --data_dir /workspace/kaggle_competition/dataset/airbus_ship_detection
    - train_v2/
    - train_ship_segmentations_v2.csv

Example run:
python3 airbus_detector_effnetv2_precision_momos.py \
  --data_dir /workspace/kaggle_competition/dataset/airbus_ship_detection \
  --out_dir  /workspace/kaggle_competition/outputs_airbus_detector \
  --model efficientnet_v2_s \
  --img_size 768 \
  --epochs 12 --batch 8 --num_workers 8 \
  --lr 2e-4 --weight_decay 1e-4 \
  --seed 42 \
  --val_ratio 0.15 \
  --use_weighted_sampler 1 \
  --target_pos_frac 0.50 \
  --min_precision 0.98 \
  --use_ship_bbox_crop 1 \
  --crop_margin_min 1.8 --crop_margin_max 4.0 \
  --early_stop_patience 3

Notes:
- If torchvision pretrained weights cannot be downloaded (offline), it automatically falls back to random init.
- Ship-aware bbox crop uses RLE->bbox parsing only (cheap), no mask rasterization required.
"""

import os
import sys
import csv
import json
import time
import math
import random
import hashlib
import argparse
from typing import Dict, List, Tuple, Optional

import numpy as np

import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler

import torchvision
from torchvision import transforms

try:
    from PIL import Image
except Exception:
    print("PIL(Pillow) is required.", file=sys.stderr)
    raise

# optional sklearn metrics
_HAS_SKLEARN = False
try:
    from sklearn.metrics import roc_auc_score
    _HAS_SKLEARN = True
except Exception:
    _HAS_SKLEARN = False


# ============================================================
# Utilities
# ============================================================
def now_str() -> str:
    return time.strftime("%Y%m%d_%H%M%S")


class Logger:
    def __init__(self, path: str, also_stdout: bool = True):
        self.path = path
        self.also_stdout = also_stdout
        os.makedirs(os.path.dirname(path), exist_ok=True)
        self.f = open(path, "w", encoding="utf-8")

    def log(self, msg: str):
        ts = time.strftime("%Y-%m-%d %H:%M:%S")
        line = f"{ts} {msg}"
        self.f.write(line + "\n")
        self.f.flush()
        if self.also_stdout:
            print(line, flush=True)

    def close(self):
        try:
            self.f.close()
        except Exception:
            pass


def seed_everything(seed: int):
    os.environ["PYTHONHASHSEED"] = str(seed)
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    # reproducibility > speed
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False


def sha1_of_file_head(path: str, nbytes: int = 1024 * 1024) -> str:
    h = hashlib.sha1()
    with open(path, "rb") as f:
        h.update(f.read(nbytes))
    return h.hexdigest()


def safe_mkdir(path: str):
    os.makedirs(path, exist_ok=True)


# ============================================================
# Airbus RLE parsing for bbox (no mask rasterization)
# - Airbus RLE is column-major (Fortran order), 1-indexed
# - Image size is 768x768
# ============================================================
def rle_to_bbox_768(rle: str, H: int = 768, W: int = 768) -> Optional[Tuple[int, int, int, int]]:
    """
    Convert a single RLE string into bbox (xmin, ymin, xmax, ymax) in pixel indices [0..W-1], [0..H-1]
    without full mask decoding.

    Returns None if rle is empty/invalid.
    """
    if rle is None:
        return None
    rle = str(rle).strip()
    if (rle == "") or (rle.lower() == "nan"):
        return None

    parts = rle.split()
    if len(parts) < 2:
        return None
    if len(parts) % 2 != 0:
        return None

    xmin, ymin = W - 1, H - 1
    xmax, ymax = 0, 0
    any_pixel = False

    # Each pair: start length (start is 1-indexed)
    for i in range(0, len(parts), 2):
        try:
            start = int(parts[i]) - 1  # to 0-index
            length = int(parts[i + 1])
        except Exception:
            continue
        if length <= 0:
            continue

        # Convert linear start to (row, col) in column-major order
        # idx = row + col*H
        row = start % H
        col = start // H

        # Run may span multiple columns; process in chunks
        remaining = length
        while remaining > 0 and col < W:
            take = min(remaining, H - row)
            if take > 0:
                any_pixel = True
                y0 = row
                y1 = row + take - 1
                x0 = col
                x1 = col

                if x0 < xmin: xmin = x0
                if x1 > xmax: xmax = x1
                if y0 < ymin: ymin = y0
                if y1 > ymax: ymax = y1

            remaining -= take
            col += 1
            row = 0

    if not any_pixel:
        return None
    return (xmin, ymin, xmax, ymax)


def union_bbox(b1: Optional[Tuple[int, int, int, int]],
               b2: Optional[Tuple[int, int, int, int]]) -> Optional[Tuple[int, int, int, int]]:
    if b1 is None:
        return b2
    if b2 is None:
        return b1
    x0 = min(b1[0], b2[0])
    y0 = min(b1[1], b2[1])
    x1 = max(b1[2], b2[2])
    y1 = max(b1[3], b2[3])
    return (x0, y0, x1, y1)


def load_pos_set_and_bbox_map(csv_path: str, build_bbox: bool) -> Tuple[set, Dict[str, Tuple[int,int,int,int]]]:
    """
    Reads train_ship_segmentations_v2.csv:
      ImageId, EncodedPixels
    POS if ImageId has at least one non-empty RLE row.
    Optionally build bbox per ImageId by unioning all RLE bboxes.

    Returns:
      pos_set, bbox_map (maybe empty if build_bbox=False)
    """
    pos = set()
    bbox_map: Dict[str, Tuple[int,int,int,int]] = {}

    with open(csv_path, "r", newline="") as f:
        r = csv.DictReader(f)
        if "ImageId" not in r.fieldnames or "EncodedPixels" not in r.fieldnames:
            raise RuntimeError(f"Unexpected CSV header: {r.fieldnames}")
        for row in r:
            img_id = row["ImageId"]
            enc = row["EncodedPixels"]
            if enc is None:
                continue
            enc = str(enc).strip()
            if enc == "" or enc.lower() == "nan":
                continue
            pos.add(img_id)

            if build_bbox:
                b = rle_to_bbox_768(enc, H=768, W=768)
                if b is not None:
                    bbox_map[img_id] = union_bbox(bbox_map.get(img_id), b)

    # Remove bbox entries that somehow ended None
    bbox_map = {k: v for k, v in bbox_map.items() if v is not None}
    return pos, bbox_map


def list_train_ids(train_img_dir: str) -> List[str]:
    exts = (".jpg", ".jpeg", ".png")
    ids = [fn for fn in os.listdir(train_img_dir) if fn.lower().endswith(exts)]
    ids.sort()
    if not ids:
        raise RuntimeError(f"No images in: {train_img_dir}")
    return ids


def stratified_split(ids: List[str], pos_set: set, val_ratio: float, seed: int) -> Dict[str, List[str]]:
    rng = np.random.default_rng(seed)
    pos_ids = [i for i in ids if i in pos_set]
    neg_ids = [i for i in ids if i not in pos_set]
    rng.shuffle(pos_ids)
    rng.shuffle(neg_ids)

    n_pos = len(pos_ids)
    n_neg = len(neg_ids)

    n_pos_val = int(round(n_pos * val_ratio))
    n_neg_val = int(round(n_neg * val_ratio))

    val = pos_ids[:n_pos_val] + neg_ids[:n_neg_val]
    train = pos_ids[n_pos_val:] + neg_ids[n_neg_val:]
    rng.shuffle(train)
    rng.shuffle(val)
    return {"train": train, "val": val}


# ============================================================
# Transforms
# ============================================================
_IMNET_MEAN = (0.485, 0.456, 0.406)
_IMNET_STD  = (0.229, 0.224, 0.225)

class AddGaussianNoise:
    def __init__(self, sigma_min: float = 0.0, sigma_max: float = 0.02, p: float = 0.3):
        self.sigma_min = float(sigma_min)
        self.sigma_max = float(sigma_max)
        self.p = float(p)

    def __call__(self, x: torch.Tensor) -> torch.Tensor:
        if random.random() > self.p:
            return x
        sigma = random.uniform(self.sigma_min, self.sigma_max)
        noise = torch.randn_like(x) * sigma
        return torch.clamp(x + noise, 0.0, 1.0)


def build_transforms(img_size: int, train: bool, strong: bool):
    """
    strong=True for POS augmentation.
    """
    if not train:
        return transforms.Compose([
            transforms.Resize((img_size, img_size), interpolation=transforms.InterpolationMode.BILINEAR),
            transforms.ToTensor(),
            transforms.Normalize(mean=_IMNET_MEAN, std=_IMNET_STD),
        ])

    if strong:
        # POS: stronger but still not too destructive
        return transforms.Compose([
            transforms.Resize((img_size, img_size), interpolation=transforms.InterpolationMode.BILINEAR),
            transforms.RandomHorizontalFlip(p=0.5),
            transforms.RandomVerticalFlip(p=0.25),
            transforms.RandomRotation(degrees=12),
            transforms.ColorJitter(brightness=0.20, contrast=0.20, saturation=0.12, hue=0.03),
            transforms.ToTensor(),
            AddGaussianNoise(0.0, 0.03, p=0.35),
            transforms.RandomErasing(p=0.15, scale=(0.01, 0.06), ratio=(0.5, 2.0), value="random"),
            transforms.Normalize(mean=_IMNET_MEAN, std=_IMNET_STD),
        ])
    else:
        # NEG: mild augmentation to avoid overfit / keep stable
        return transforms.Compose([
            transforms.Resize((img_size, img_size), interpolation=transforms.InterpolationMode.BILINEAR),
            transforms.RandomHorizontalFlip(p=0.35),
            transforms.RandomVerticalFlip(p=0.10),
            transforms.ColorJitter(brightness=0.08, contrast=0.08, saturation=0.05, hue=0.01),
            transforms.ToTensor(),
            transforms.Normalize(mean=_IMNET_MEAN, std=_IMNET_STD),
        ])


# ============================================================
# Dataset (optional ship-aware bbox crop for POS)
# ============================================================
def clamp_int(v: int, lo: int, hi: int) -> int:
    return max(lo, min(hi, int(v)))

def make_square_crop_from_bbox(
    bbox: Tuple[int,int,int,int],
    H: int,
    W: int,
    margin_scale: float
) -> Tuple[int,int,int,int]:
    """
    bbox: (xmin,ymin,xmax,ymax). Return square crop (left, top, right, bottom) inclusive bounds.
    margin_scale enlarges bbox size (e.g., 2.0 means side length ~2x max(w,h)).
    """
    x0,y0,x1,y1 = bbox
    bw = (x1 - x0 + 1)
    bh = (y1 - y0 + 1)
    side = int(math.ceil(max(bw, bh) * margin_scale))
    side = max(side, 32)
    cx = (x0 + x1) / 2.0
    cy = (y0 + y1) / 2.0

    left = int(round(cx - side / 2.0))
    top  = int(round(cy - side / 2.0))
    right = left + side - 1
    bottom = top + side - 1

    # shift to fit within image
    if left < 0:
        shift = -left
        left += shift; right += shift
    if top < 0:
        shift = -top
        top += shift; bottom += shift
    if right >= W:
        shift = right - (W - 1)
        left -= shift; right -= shift
    if bottom >= H:
        shift = bottom - (H - 1)
        top -= shift; bottom -= shift

    left = clamp_int(left, 0, W-1)
    right = clamp_int(right, 0, W-1)
    top = clamp_int(top, 0, H-1)
    bottom = clamp_int(bottom, 0, H-1)

    # ensure valid
    if right <= left:
        right = min(W-1, left + 1)
    if bottom <= top:
        bottom = min(H-1, top + 1)

    return (left, top, right, bottom)


class AirbusDetectorDataset(Dataset):
    def __init__(
        self,
        img_dir: str,
        image_ids: List[str],
        pos_set: set,
        tfm_pos,
        tfm_neg,
        tfm_val,
        train: bool,
        use_ship_bbox_crop: bool,
        bbox_map: Dict[str, Tuple[int,int,int,int]],
        crop_margin_min: float,
        crop_margin_max: float,
    ):
        self.img_dir = img_dir
        self.ids = image_ids
        self.pos_set = pos_set
        self.tfm_pos = tfm_pos
        self.tfm_neg = tfm_neg
        self.tfm_val = tfm_val
        self.train = bool(train)
        self.use_ship_bbox_crop = bool(use_ship_bbox_crop)
        self.bbox_map = bbox_map
        self.crop_margin_min = float(crop_margin_min)
        self.crop_margin_max = float(crop_margin_max)

    def __len__(self):
        return len(self.ids)

    def __getitem__(self, idx: int):
        img_id = self.ids[idx]
        path = os.path.join(self.img_dir, img_id)
        img = Image.open(path).convert("RGB")

        is_pos = (img_id in self.pos_set)
        y = torch.tensor([1.0 if is_pos else 0.0], dtype=torch.float32)

        if not self.train:
            x = self.tfm_val(img)
            return x, y, img_id

        # Training path
        if is_pos:
            # optional ship-aware crop (cheap)
            if self.use_ship_bbox_crop and (img_id in self.bbox_map):
                bbox = self.bbox_map[img_id]
                m = random.uniform(self.crop_margin_min, self.crop_margin_max)
                left, top, right, bottom = make_square_crop_from_bbox(bbox, H=768, W=768, margin_scale=m)
                img = img.crop((left, top, right + 1, bottom + 1))  # PIL crop uses [left, top, right, bottom) end-exclusive
            x = self.tfm_pos(img)
        else:
            x = self.tfm_neg(img)

        return x, y, img_id


# ============================================================
# Model
# ============================================================
def build_model(model_name: str, num_classes: int = 1, pretrained: bool = True, log: Optional[Logger] = None) -> nn.Module:
    """
    torchvision EfficientNetV2:
      - efficientnet_v2_s / _m / _l
    Output: single logit for BCEWithLogitsLoss
    """
    model_name = model_name.strip().lower()

    def _log(msg: str):
        if log is not None:
            log.log(msg)
        else:
            print(msg, flush=True)

    weights = None
    if pretrained:
        try:
            if model_name == "efficientnet_v2_s":
                weights = torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1
            elif model_name == "efficientnet_v2_m":
                weights = torchvision.models.EfficientNet_V2_M_Weights.IMAGENET1K_V1
            elif model_name == "efficientnet_v2_l":
                weights = torchvision.models.EfficientNet_V2_L_Weights.IMAGENET1K_V1
            else:
                raise ValueError(f"Unsupported model: {model_name}")
        except Exception:
            weights = None

    try:
        if model_name == "efficientnet_v2_s":
            m = torchvision.models.efficientnet_v2_s(weights=weights)
        elif model_name == "efficientnet_v2_m":
            m = torchvision.models.efficientnet_v2_m(weights=weights)
        elif model_name == "efficientnet_v2_l":
            m = torchvision.models.efficientnet_v2_l(weights=weights)
        else:
            raise ValueError(f"Unsupported model: {model_name}")
        _log(f"[MODEL] built {model_name} pretrained={pretrained} weights={'OK' if weights is not None else 'None'}")
    except Exception as e:
        # fallback: no pretrained
        _log(f"[WARN] failed to load pretrained weights: {repr(e)}")
        _log("[WARN] fallback to random init (pretrained=False)")
        if model_name == "efficientnet_v2_s":
            m = torchvision.models.efficientnet_v2_s(weights=None)
        elif model_name == "efficientnet_v2_m":
            m = torchvision.models.efficientnet_v2_m(weights=None)
        elif model_name == "efficientnet_v2_l":
            m = torchvision.models.efficientnet_v2_l(weights=None)
        else:
            raise ValueError(f"Unsupported model: {model_name}")

    in_features = m.classifier[-1].in_features
    m.classifier[-1] = nn.Linear(in_features, num_classes)
    return m


# ============================================================
# Metrics & Threshold selection (High Precision constraint)
# ============================================================
@torch.no_grad()
def predict_probs(model: nn.Module, loader: DataLoader, device: torch.device) -> Tuple[np.ndarray, np.ndarray]:
    model.eval()
    probs = []
    gts = []
    for x, y, _ in loader:
        x = x.to(device, non_blocking=True)
        y = y.to(device, non_blocking=True)
        logit = model(x)
        prob = torch.sigmoid(logit).detach().cpu().numpy().reshape(-1)
        gt = y.detach().cpu().numpy().reshape(-1)
        probs.append(prob)
        gts.append(gt)
    p = np.concatenate(probs, axis=0).astype(np.float32)
    t = np.concatenate(gts, axis=0).astype(np.float32)
    return p, t


def select_threshold_high_precision(
    y_prob: np.ndarray,
    y_true: np.ndarray,
    min_precision: float = 0.98,
) -> Tuple[float, Dict[str, float]]:
    """
    Choose threshold that maximizes ACCURACY subject to Precision >= min_precision.
    If no threshold can satisfy min_precision (rare), fallback to threshold=1.0 (predict all NEG).

    Efficient method: sort probs descending, consider predicting POS for top-k.
    threshold = prob_sorted[k-1] (or slightly below).
    """
    assert y_prob.ndim == 1 and y_true.ndim == 1
    eps = 1e-12
    N = int(y_true.shape[0])
    pos_total = float(y_true.sum())
    neg_total = float(N - pos_total)

    # Sort by prob descending
    idx = np.argsort(-y_prob)
    p_sorted = y_prob[idx]
    t_sorted = y_true[idx]

    # cumulative TP/FP when predicting POS for first k samples
    tp_cum = np.cumsum(t_sorted)
    fp_cum = np.cumsum(1.0 - t_sorted)

    best_acc = -1.0
    best_thr = 1.0
    best_pack: Dict[str, float] = {
        "thr": 1.0, "acc": 0.0, "precision": 0.0, "recall": 0.0, "f1": 0.0,
        "tp": 0.0, "fp": 0.0, "fn": pos_total, "tn": neg_total, "min_precision": float(min_precision)
    }

    # k=0 => predict all NEG => precision undefined; treat as precision=1 if tp=0? we define precision=1 (no positive predictions)
    # accuracy = tn/N
    tn0 = neg_total
    acc0 = tn0 / max(1.0, N)
    if 1.0 >= min_precision:
        best_acc = acc0
        best_thr = 1.0
        best_pack.update({
            "thr": 1.0, "acc": float(acc0),
            "precision": 1.0, "recall": 0.0, "f1": 0.0,
            "tp": 0.0, "fp": 0.0, "fn": float(pos_total), "tn": float(neg_total),
        })

    # scan k=1..N
    for k in range(1, N + 1):
        tp = float(tp_cum[k - 1])
        fp = float(fp_cum[k - 1])
        fn = float(pos_total - tp)
        tn = float(neg_total - fp)

        precision = tp / (tp + fp + eps)
        if precision + 1e-15 < min_precision:
            # as k increases, precision can go up or down; cannot early break safely.
            continue

        recall = tp / (tp + fn + eps)
        f1 = (2.0 * precision * recall) / (precision + recall + eps)
        acc = (tp + tn) / max(1.0, N)

        if acc > best_acc:
            best_acc = acc
            thr = float(p_sorted[k - 1])
            best_thr = thr
            best_pack = {
                "thr": float(thr),
                "acc": float(acc),
                "precision": float(precision),
                "recall": float(recall),
                "f1": float(f1),
                "tp": float(tp),
                "fp": float(fp),
                "fn": float(fn),
                "tn": float(tn),
                "min_precision": float(min_precision),
            }

    return float(best_thr), best_pack


@torch.no_grad()
def evaluate_at_threshold(
    y_prob: np.ndarray,
    y_true: np.ndarray,
    thr: float
) -> Dict[str, float]:
    eps = 1e-12
    y_pred = (y_prob >= float(thr)).astype(np.int32)
    y_true_i = y_true.astype(np.int32)

    tp = float(((y_pred == 1) & (y_true_i == 1)).sum())
    fp = float(((y_pred == 1) & (y_true_i == 0)).sum())
    fn = float(((y_pred == 0) & (y_true_i == 1)).sum())
    tn = float(((y_pred == 0) & (y_true_i == 0)).sum())

    precision = tp / (tp + fp + eps) if (tp + fp) > 0 else 1.0
    recall = tp / (tp + fn + eps) if (tp + fn) > 0 else 0.0
    f1 = (2.0 * precision * recall) / (precision + recall + eps) if (precision + recall) > 0 else 0.0
    acc = (tp + tn) / max(1.0, len(y_true))

    out = {
        "thr": float(thr),
        "acc": float(acc),
        "precision": float(precision),
        "recall": float(recall),
        "f1": float(f1),
        "tp": float(tp),
        "fp": float(fp),
        "fn": float(fn),
        "tn": float(tn),
        "n": float(len(y_true)),
        "pos_rate": float(y_true.mean()) if len(y_true) > 0 else 0.0,
    }

    if _HAS_SKLEARN:
        try:
            if (y_true.max() > 0.0) and (y_true.min() < 1.0):
                out["auroc"] = float(roc_auc_score(y_true, y_prob))
            else:
                out["auroc"] = float("nan")
        except Exception:
            out["auroc"] = float("nan")
    else:
        out["auroc"] = float("nan")

    return out


# ============================================================
# Train
# ============================================================
def train_one_epoch(
    model: nn.Module,
    loader: DataLoader,
    device: torch.device,
    optimizer: torch.optim.Optimizer,
    criterion: nn.Module,
    epoch: int,
    log: Logger,
    grad_clip: float = 0.0,
    log_every: int = 50,
) -> Dict[str, float]:
    model.train()
    loss_sum = 0.0
    n = 0
    t0 = time.time()

    for it, (x, y, _) in enumerate(loader, start=1):
        x = x.to(device, non_blocking=True)
        y = y.to(device, non_blocking=True)

        optimizer.zero_grad(set_to_none=True)
        logit = model(x)
        loss = criterion(logit, y)
        loss.backward()

        if grad_clip and grad_clip > 0:
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=float(grad_clip))

        optimizer.step()

        bs = int(y.shape[0])
        loss_sum += float(loss.item()) * bs
        n += bs

        if log_every > 0 and (it % log_every) == 0:
            log.log(f"[TRAIN] epoch={epoch} iter={it}/{len(loader)} loss={loss.item():.6f}")

    dt = time.time() - t0
    return {"train_loss": float(loss_sum / max(1, n)), "train_n": float(n), "sec": float(dt)}


def main():
    ap = argparse.ArgumentParser()

    ap.add_argument("--data_dir", type=str, required=True)
    ap.add_argument("--out_dir", type=str, required=True)

    ap.add_argument("--model", type=str, default="efficientnet_v2_s")
    ap.add_argument("--img_size", type=int, default=768)
    ap.add_argument("--pretrained", type=int, default=1)

    ap.add_argument("--epochs", type=int, default=12)
    ap.add_argument("--batch", type=int, default=8)
    ap.add_argument("--num_workers", type=int, default=8)

    ap.add_argument("--lr", type=float, default=2e-4)
    ap.add_argument("--weight_decay", type=float, default=1e-4)

    ap.add_argument("--seed", type=int, default=42)
    ap.add_argument("--val_ratio", type=float, default=0.15)

    # Oversampling (NOT subsampling): make POS appear more frequently
    ap.add_argument("--use_weighted_sampler", type=int, default=1)
    ap.add_argument("--target_pos_frac", type=float, default=0.50)  # target POS fraction per epoch via sampling

    # Loss shaping
    ap.add_argument("--pos_weight", type=float, default=0.0, help="BCE pos_weight; 0 => auto (neg/pos clipped)")
    ap.add_argument("--label_smoothing", type=float, default=0.0)

    # High precision threshold selection
    ap.add_argument("--min_precision", type=float, default=0.98)

    # Optional ship-aware bbox crop (cheap alternative to inpainting)
    ap.add_argument("--use_ship_bbox_crop", type=int, default=1)
    ap.add_argument("--crop_margin_min", type=float, default=1.8)
    ap.add_argument("--crop_margin_max", type=float, default=4.0)

    # Early stopping on constrained-accuracy
    ap.add_argument("--early_stop_patience", type=int, default=3)

    # Misc
    ap.add_argument("--grad_clip", type=float, default=0.0)
    ap.add_argument("--save_every", type=int, default=1)
    ap.add_argument("--log_every", type=int, default=50)

    args = ap.parse_args()

    seed_everything(args.seed)

    train_img_dir = os.path.join(args.data_dir, "train_v2")
    train_csv = os.path.join(args.data_dir, "train_ship_segmentations_v2.csv")
    if not os.path.exists(train_img_dir):
        raise RuntimeError(f"train_v2 not found: {train_img_dir}")
    if not os.path.exists(train_csv):
        raise RuntimeError(f"train_ship_segmentations_v2.csv not found: {train_csv}")

    # Build POS set and bbox_map (optional)
    build_bbox = (int(args.use_ship_bbox_crop) == 1)
    pos_set, bbox_map = load_pos_set_and_bbox_map(train_csv, build_bbox=build_bbox)

    all_ids = list_train_ids(train_img_dir)
    splits = stratified_split(all_ids, pos_set, val_ratio=float(args.val_ratio), seed=int(args.seed))
    train_ids = splits["train"]
    val_ids = splits["val"]

    # Run dir naming (reproducible)
    run_name = (
        f"run__detector_prec_{args.model}__img{args.img_size}"
        f"__seed{args.seed}__train{len(train_ids)}__val{len(val_ids)}__valr{args.val_ratio:.2f}"
        f"__tpos{args.target_pos_frac:.2f}__pmin{args.min_precision:.2f}"
        f"__bbox{int(args.use_ship_bbox_crop)}"
    )
    run_dir = os.path.join(args.out_dir, run_name)
    safe_mkdir(run_dir)

    log = Logger(os.path.join(run_dir, "train.log"), also_stdout=True)
    log.log("==== START: Airbus Detector (EfficientNetV2) — High Precision Mode ====")
    log.log(f"run_dir={run_dir}")
    log.log(f"data_dir={args.data_dir}")
    log.log(f"train_img_dir={train_img_dir}")
    log.log(f"train_csv={train_csv}")
    log.log(f"sklearn_available={_HAS_SKLEARN}")
    log.log(f"ALL images={len(all_ids)} POS={len(pos_set)} POS_rate={len(pos_set)/len(all_ids):.4f}")
    if build_bbox:
        log.log(f"bbox_map size={len(bbox_map)} (POS with bbox parsed)")

    # Save config & splits
    with open(os.path.join(run_dir, "config.json"), "w", encoding="utf-8") as f:
        json.dump(vars(args), f, indent=2, ensure_ascii=False)

    with open(os.path.join(run_dir, "splits.json"), "w", encoding="utf-8") as f:
        json.dump({
            "seed": args.seed,
            "val_ratio": args.val_ratio,
            "train_n": len(train_ids),
            "val_n": len(val_ids),
            "train_ids": train_ids,
            "val_ids": val_ids,
        }, f, indent=2, ensure_ascii=False)

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    log.log(f"device={device}")

    # Build transforms
    tfm_pos = build_transforms(args.img_size, train=True, strong=True)
    tfm_neg = build_transforms(args.img_size, train=True, strong=False)
    tfm_val = build_transforms(args.img_size, train=False, strong=False)

    ds_train = AirbusDetectorDataset(
        img_dir=train_img_dir,
        image_ids=train_ids,
        pos_set=pos_set,
        tfm_pos=tfm_pos,
        tfm_neg=tfm_neg,
        tfm_val=tfm_val,
        train=True,
        use_ship_bbox_crop=(int(args.use_ship_bbox_crop) == 1),
        bbox_map=bbox_map,
        crop_margin_min=args.crop_margin_min,
        crop_margin_max=args.crop_margin_max,
    )
    ds_val = AirbusDetectorDataset(
        img_dir=train_img_dir,
        image_ids=val_ids,
        pos_set=pos_set,
        tfm_pos=tfm_pos,
        tfm_neg=tfm_neg,
        tfm_val=tfm_val,
        train=False,
        use_ship_bbox_crop=False,
        bbox_map=bbox_map,
        crop_margin_min=args.crop_margin_min,
        crop_margin_max=args.crop_margin_max,
    )

    # Weighted sampler (oversample POS to target fraction; NO subsampling)
    sampler = None
    shuffle = True
    if int(args.use_weighted_sampler) == 1:
        labels = np.array([1 if i in pos_set else 0 for i in train_ids], dtype=np.int64)
        n_pos = int(labels.sum())
        n_neg = int(len(labels) - n_pos)
        if n_pos == 0 or n_neg == 0:
            log.log("[WARN] sampler disabled due to single-class train split.")
        else:
            target_pos = float(args.target_pos_frac)
            target_pos = max(1e-6, min(1.0 - 1e-6, target_pos))
            target_neg = 1.0 - target_pos
            w_pos = target_pos / max(1, n_pos)
            w_neg = target_neg / max(1, n_neg)
            weights = np.where(labels == 1, w_pos, w_neg).astype(np.float64)
            weights_t = torch.from_numpy(weights)
            sampler = WeightedRandomSampler(
                weights=weights_t,
                num_samples=len(train_ids),  # one epoch = same #updates as dataset size; replacement=True
                replacement=True
            )
            shuffle = False
            log.log(f"[SAMPLER] enabled: n_pos={n_pos} n_neg={n_neg} target_pos_frac={target_pos:.3f} w_pos={w_pos:.6e} w_neg={w_neg:.6e}")

    dl_train = DataLoader(
        ds_train,
        batch_size=int(args.batch),
        shuffle=shuffle,
        sampler=sampler,
        num_workers=int(args.num_workers),
        pin_memory=True,
        drop_last=True,
        persistent_workers=(int(args.num_workers) > 0),
    )
    dl_val = DataLoader(
        ds_val,
        batch_size=max(1, int(args.batch)),
        shuffle=False,
        num_workers=int(args.num_workers),
        pin_memory=True,
        drop_last=False,
        persistent_workers=(int(args.num_workers) > 0),
    )

    # Build model
    model = build_model(args.model, num_classes=1, pretrained=(int(args.pretrained) == 1), log=log).to(device)

    # Loss: BCEWithLogitsLoss with pos_weight (optional)
    if args.pos_weight and float(args.pos_weight) > 0:
        pos_weight = float(args.pos_weight)
        log.log(f"[LOSS] pos_weight(user)={pos_weight}")
    else:
        # auto from real split distribution (stable even if sampler oversamples)
        labels_pw = np.array([1 if i in pos_set else 0 for i in train_ids], dtype=np.int64)
        n_pos = float(labels_pw.sum())
        n_neg = float(len(labels_pw) - labels_pw.sum())
        pos_weight = float(n_neg / max(1.0, n_pos))
        pos_weight = float(min(50.0, max(1.0, pos_weight)))
        log.log(f"[LOSS] pos_weight(auto)={pos_weight:.4f} (neg/pos clipped)")

    bce = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([pos_weight], device=device))

    def criterion(logit, y):
        if args.label_smoothing and float(args.label_smoothing) > 0:
            s = float(args.label_smoothing)
            y_sm = y * (1.0 - s) + 0.5 * s
            return bce(logit, y_sm)
        return bce(logit, y)

    optimizer = torch.optim.AdamW(model.parameters(), lr=float(args.lr), weight_decay=float(args.weight_decay))

    # Scheduler: cosine decay (simple, stable)
    total_steps = max(1, int(args.epochs) * max(1, len(dl_train)))
    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=total_steps, eta_min=float(args.lr) * 0.05)

    # Training loop with early stopping on "constrained accuracy" (precision >= min_precision)
    best_score = -1.0
    best_epoch = -1
    best_thr = 1.0
    best_val_metrics = {}
    no_improve = 0

    for epoch in range(1, int(args.epochs) + 1):
        tr = train_one_epoch(
            model=model,
            loader=dl_train,
            device=device,
            optimizer=optimizer,
            criterion=criterion,
            epoch=epoch,
            log=log,
            grad_clip=float(args.grad_clip),
            log_every=int(args.log_every),
        )

        # Step scheduler per iteration (cosine)
        # Since we used step-per-iter schedule, we advanced only at epoch end above.
        # We'll advance here in a tight loop to match step count.
        # (This keeps behavior deterministic even if dataloader length changes.)
        for _ in range(len(dl_train)):
            scheduler.step()

        # VAL: predict probs, select threshold to maximize ACC with precision constraint
        y_prob, y_true = predict_probs(model, dl_val, device=device)
        thr, pack = select_threshold_high_precision(y_prob, y_true, min_precision=float(args.min_precision))
        val_metrics = evaluate_at_threshold(y_prob, y_true, thr=thr)

        # Add constrained selection stats
        val_metrics["constrained_select_acc"] = float(pack.get("acc", val_metrics["acc"]))
        val_metrics["constrained_select_precision"] = float(pack.get("precision", val_metrics["precision"]))
        val_metrics["constrained_select_recall"] = float(pack.get("recall", val_metrics["recall"]))
        val_metrics["constrained_select_f1"] = float(pack.get("f1", val_metrics["f1"]))
        val_metrics["min_precision"] = float(args.min_precision)

        score = float(pack.get("acc", val_metrics["acc"]))  # constrained accuracy

        log.log(
            f"[EPOCH] {epoch}/{args.epochs} "
            f"train_loss={tr['train_loss']:.6f} "
            f"VAL: thr={thr:.5f} "
            f"acc={val_metrics['acc']:.5f} "
            f"p={val_metrics['precision']:.5f} r={val_metrics['recall']:.5f} f1={val_metrics['f1']:.5f} "
            f"auroc={val_metrics['auroc']:.5f} "
            f"(constrained_acc={score:.5f} minP={args.min_precision:.3f})"
        )

        # Save last checkpoint
        if (epoch % max(1, int(args.save_every))) == 0:
            last_path = os.path.join(run_dir, "last_model.pt")
            torch.save({
                "epoch": epoch,
                "model": model.state_dict(),
                "config": vars(args),
                "val_thr": float(thr),
                "val_metrics": val_metrics,
            }, last_path)

        # Update best
        if score > best_score + 1e-12:
            best_score = float(score)
            best_epoch = int(epoch)
            best_thr = float(thr)
            best_val_metrics = dict(val_metrics)
            no_improve = 0

            best_path = os.path.join(run_dir, "best_model.pt")
            torch.save({
                "epoch": epoch,
                "model": model.state_dict(),
                "config": vars(args),
                "best_thr": float(best_thr),
                "val_metrics": best_val_metrics,
            }, best_path)
            log.log(f"[BEST] epoch={best_epoch} constrained_acc={best_score:.6f} best_thr={best_thr:.5f} saved={best_path}")
        else:
            no_improve += 1
            log.log(f"[EARLYSTOP] no_improve={no_improve}/{int(args.early_stop_patience)}")

        if int(args.early_stop_patience) > 0 and no_improve >= int(args.early_stop_patience):
            log.log("[EARLYSTOP] triggered. stop training.")
            break

    # Write best metrics summary
    best_json = os.path.join(run_dir, "metrics_val_best.json")
    with open(best_json, "w", encoding="utf-8") as f:
        json.dump({
            "best_epoch": best_epoch,
            "best_score_constrained_acc": best_score,
            "best_thr": best_thr,
            "min_precision": float(args.min_precision),
            "best_val_metrics": best_val_metrics,
            "best_model_path": os.path.join(run_dir, "best_model.pt"),
        }, f, indent=2, ensure_ascii=False)

    # Final report
    best_model_path = os.path.join(run_dir, "best_model.pt")
    head_sha1 = sha1_of_file_head(best_model_path) if os.path.exists(best_model_path) else "NA"

    log.log("==== DONE ====")
    log.log(f"run_dir={run_dir}")
    log.log(f"best_epoch={best_epoch} best_constrained_acc={best_score:.6f} best_thr={best_thr:.5f} minP={args.min_precision:.3f}")
    log.log(f"best_model.pt sha1(first1MB)={head_sha1}")
    log.log(f"best_val_metrics={json.dumps(best_val_metrics, ensure_ascii=False)}")
    log.close()


if __name__ == "__main__":
    main()
